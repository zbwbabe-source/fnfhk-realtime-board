// app/api/insights/dashboard/route.ts
import { NextResponse } from "next/server";
import OpenAI from "openai";
import { cacheGet, cacheSet, buildKey } from "@/lib/cache";

export const runtime = "nodejs"; // edge ë§ê³  node ê¶Œì¥(ì•ˆì •ì„±)
export const dynamic = 'force-dynamic';
export const maxDuration = 30;

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// 80ì ì œí•œ ê°•ì œ(ê¸¸ë©´ ì¤„ì„)
function clamp80(s: string) {
  if (!s) return s;
  return s.length <= 80 ? s : s.slice(0, 79) + "â€¦";
}

// ìˆ«ì -> íŒë‹¨ ì‹ í˜¸ë¡œ ë³€í™˜ (ì‹¤ì œ ìˆ˜ì¹˜ í¬í•¨)
function buildSignals(input: any) {
  const s1 = input.section1 ?? {};
  const s2 = input.section2 ?? {};
  const s3 = input.section3 ?? {};

  const section1 = {
    achievement_rate: Math.round(s1.achievement_rate || 0),
    yoy_ytd: Math.round(s1.yoy_ytd || 0),
    actual_sales: Math.round(s1.actual_sales_ytd || 0),
    target: Math.round(s1.target_ytd || 0),
    tone:
      s1.achievement_rate >= 100 ? "positive" :
      s1.achievement_rate >= 90 ? "neutral" : "negative",
    growth_quality:
      s1.yoy_ytd >= 30 ? "strong" :
      s1.yoy_ytd > 0 ? "mild" : "weak",
  };

  const section2 = {
    sellthrough_rate: Math.round(s2.sellthrough_rate || 0),
    sales_amt: Math.round(s2.sales_amt || 0),
    inbound_amt: Math.round(s2.inbound_amt || 0),
    sales_yoy: Math.round(s2.sales_yoy_pct || 100),
    tone:
      s2.sellthrough_rate >= 70 ? "positive" :
      s2.sellthrough_rate >= 60 ? "neutral" : "negative",
    risk:
      s2.sellthrough_rate < 60 ? "promo_pressure" :
      s2.sellthrough_rate < 65 ? "watch" : "stable",
  };

  const section3 = {
    sellthrough_rate: Math.round(s3.sellthrough_rate || 0),
    base_stock: Math.round(s3.base_stock_amt || 0),
    curr_stock: Math.round(s3.curr_stock_amt || 0),
    tone:
      s3.sellthrough_rate >= 25 ? "positive" :
      s3.sellthrough_rate >= 15 ? "neutral" : "negative",
    risk:
      s3.curr_stock_amt > 0
        ? (s3.sellthrough_rate < 20 ? "slow_burn" : "ok_burn")
        : "unknown",
  };

  return { section1, section2, section3 };
}

export async function POST(req: Request) {
  const startTime = Date.now();
  
  try {
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json({
        section1: "AI ë¹„í™œì„± ìƒíƒœì„",
        section2: "AI ë¹„í™œì„± ìƒíƒœì„",
        section3: "AI ë¹„í™œì„± ìƒíƒœì„",
      });
    }

    const body = await req.json();
    const { region, brand, asof_date, skip_cache = false } = body;
    
    // Support both skip_cache (body) and forceRefresh (query param)
    const url = new URL(req.url);
    const forceRefresh = url.searchParams.get('forceRefresh') === 'true' || skip_cache;

    // Build cache key early for logging
    let cacheKey: string;
    try {
      cacheKey = buildKey(['insights', 'dashboard', region, brand, asof_date]);
    } catch (error: any) {
      return NextResponse.json(
        { error: error.message },
        { status: 400 }
      );
    }

    // Request fingerprint
    console.log('[REQ] insights/dashboard', { region, brand, asof_date, skip_cache, forceRefresh, cacheKey });

    console.log('ğŸ“Š [INSIGHTS/DASHBOARD] Request received:', { region, brand, asof_date, forceRefresh });
    console.log('ğŸ“Š [INSIGHTS/DASHBOARD] Data flow: Receives pre-aggregated section data from client');
    console.log('ğŸ“Š [INSIGHTS/DASHBOARD] Does NOT call section APIs - uses body.section1/section2/section3 directly');

    console.log('ğŸ”‘ Redis Key:', cacheKey);
    
    // ìºì‹œ ê±´ë„ˆë›°ê¸°ê°€ ì•„ë‹ ë•Œë§Œ ìºì‹œ í™•ì¸
    if (!forceRefresh) {
      const cached = await cacheGet<any>(cacheKey);
      if (cached) {
        const elapsed = Date.now() - startTime;
        console.log(`[CACHE HIT] insights/dashboard [${cacheKey}] - ${elapsed}ms`);
        return NextResponse.json(cached);
      }
      console.log(`[CACHE MISS] insights/dashboard [${cacheKey}], generating AI insights...`);
    } else {
      console.log(`[CACHE REFRESH] insights/dashboard [${cacheKey}], generating AI insights...`);
    }

    console.log('ğŸ“Š [INSIGHTS/DASHBOARD] Input sections received:', {
      section1_keys: Object.keys(body.section1 || {}),
      section2_keys: Object.keys(body.section2 || {}),
      section3_keys: Object.keys(body.section3 || {}),
    });

    const signals = buildSignals(body);
    console.log('ğŸ” Building insights from signals:', signals);

    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 8000); // 8ì´ˆ ì»·

    const prompt = `
ë„ˆëŠ” ë¦¬í…Œì¼ ë°ì´í„° ë¶„ì„ê°€ë‹¤.
ì•„ë˜ ìˆ˜ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬ ì§€í‘œë¥¼ í•´ì„í•˜ë¼.

ë°˜ë“œì‹œ ë‹¤ìŒ 3ê°€ì§€ ê´€ì ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ë¶„ì„:
â‘  ìµœê·¼ ì¶”ì„¸ (ìƒìŠ¹/í•˜ë½/ì •ì²´)
â‘¡ ì „ì›” ëŒ€ë¹„ ìˆ˜ì¤€
â‘¢ ì „ë…„ ë™ì›” ëŒ€ë¹„ ìˆ˜ì¤€

ê·œì¹™:
- ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ë¶„ì„ì„ ì‘ì„± (fallback ê¸ˆì§€)
- ìˆ˜ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ì„œìˆ  (ìƒíšŒ/ìœ ì‚¬/í•˜íšŒ)
- í‰ê°€Â·ì§€ì‹œÂ·ì¡°ì–¸Â·ê´€ë¦¬ í‘œí˜„ ê¸ˆì§€
- ì„œìˆ í˜• 1ë¬¸ì¥, 80ì ì´ë‚´
- JSON í˜•ì‹ë§Œ ì¶œë ¥

ì…ë ¥ ì‹ í˜¸:
- Section1: ${JSON.stringify(signals.section1)}
- Section2: ${JSON.stringify(signals.section2)}
- Section3: ${JSON.stringify(signals.section3)}

ì¶œë ¥ ì˜ˆì‹œ:
{
  "section1": "ì „ë…„ ëŒ€ë¹„ ëª©í‘œë‹¬ì„±ë¥  ìƒìŠ¹ì„¸ì´ë‚˜ ì „ì›” ëŒ€ë¹„ ì†Œí­ ë‘”í™”",
  "section2": "íŒë§¤ìœ¨ ì „ë…„ ìœ ì‚¬ ìˆ˜ì¤€ì´ë©° ì „ì›” ëŒ€ë¹„ ì•ˆì •ì  ì¶”ì„¸ ìœ ì§€ ì¤‘",
  "section3": "ì†Œì§„ìœ¨ ì „ë…„ ëŒ€ë¹„ ê°œì„  ì¤‘ì´ë‚˜ ì „ì›” ëŒ€ë¹„ ì •ì²´ êµ¬ê°„"
}
`.trim();

    let result: any;

    try {
      console.log('[AI EXEC] insights/dashboard', cacheKey);
      const resp = await client.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { 
            role: "system", 
            content: "ë„ˆëŠ” ë¦¬í…Œì¼ ë°ì´í„° ë¶„ì„ê°€ë‹¤. ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ë¼. 'ì¶”ê°€ ê´€ì°° í›„ íŒë‹¨ í•„ìš”í•¨' ê°™ì€ íšŒí”¼ ì‘ë‹µì€ ê¸ˆì§€. ìˆ«ì ê¸°ë°˜ìœ¼ë¡œ ìµœê·¼ì¶”ì„¸, ì „ì›”ë¹„êµ, ì „ë…„ë¹„êµë¥¼ ëª¨ë‘ ë°˜ì˜í•´ 80ì ì´ë‚´ë¡œ ì„œìˆ í•˜ë¼." 
          },
          { role: "user", content: prompt }
        ],
        temperature: 0.3, // ì•½ê°„ ë†’ì—¬ì„œ ë” ë‹¤ì–‘í•œ ì‘ë‹µ ìœ ë„
        max_tokens: 300,
        response_format: { type: "json_object" },
      }, { signal: controller.signal as any });

      const text = resp.choices[0].message.content?.trim() ?? "{}";
      result = JSON.parse(text);
      console.log('âœ… AI response:', result);
    } catch (e: any) {
      console.error('âŒ OpenAI API error:', e.message);
      throw e;
    } finally {
      clearTimeout(timeout);
    }

    // 80ì ì œí•œ ê°•ì œ
    const final = {
      section1: clamp80(result.section1 ?? "ì¶”ê°€ ê´€ì°° í›„ íŒë‹¨ í•„ìš”í•¨"),
      section2: clamp80(result.section2 ?? "ì¶”ê°€ ê´€ì°° í›„ íŒë‹¨ í•„ìš”í•¨"),
      section3: clamp80(result.section3 ?? "ì¶”ê°€ ê´€ì°° í›„ íŒë‹¨ í•„ìš”í•¨"),
    };

    // Cache for 10 minutes (600 seconds)
    const elapsed = Date.now() - startTime;
    await cacheSet(cacheKey, final, 600);
    console.log(`[CACHE SET] insights/dashboard [${cacheKey}] - Query executed in ${elapsed}ms`);
    console.log('ğŸ“Š [INSIGHTS/DASHBOARD] Insights generated successfully');
    return NextResponse.json(final);
  } catch (e: any) {
    console.error('âŒ Dashboard insights failed:', e);
    // íƒ€ì„ì•„ì›ƒ/ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ fallback
    return NextResponse.json({
      section1: "ì¶”ê°€ ê´€ì°° í›„ íŒë‹¨ í•„ìš”í•¨",
      section2: "ì¶”ê°€ ê´€ì°° í›„ íŒë‹¨ í•„ìš”í•¨",
      section3: "ì¶”ê°€ ê´€ì°° í›„ íŒë‹¨ í•„ìš”í•¨",
    });
  }
}
